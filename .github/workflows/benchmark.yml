name: Performance Benchmarks

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Run benchmarks daily at 2 AM UTC
    - cron: "0 2 * * *"
  workflow_dispatch:
    inputs:
      benchmark_filter:
        description: "Benchmark filter (e.g., SearchBenchmarks)"
        required: false
        default: ""

jobs:
  benchmark:
    # Use specific runner for consistent benchmark results
    runs-on: ubuntu-22.04 # 4 cores, 16GB RAM, consistent specs
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for ASV

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v2

      - name: Install dependencies
        run: uv sync --extra bench
        env:
          HATCH_BUILD_NO_HOOKS: true

      - name: Build schema data
        run: uv run build-schemas --ids-filter "equilibrium core_profiles" --quiet

      - name: Build embeddings
        run: uv run build-embeddings --ids-filter "equilibrium core_profiles" --quiet --no-cache

      - name: Verify schema files
        run: |
          echo "Checking for required schema files..."
          ls -la imas_mcp/resources/schemas/ || true
          if [ -f "imas_mcp/resources/schemas/ids_catalog.json" ]; then
            echo "✅ ids_catalog.json found"
            wc -l imas_mcp/resources/schemas/ids_catalog.json
          else
            echo "❌ ids_catalog.json missing"
            exit 1
          fi

      - name: Download previous benchmark results
        uses: actions/download-artifact@v4
        with:
          name: asv-results
          path: .asv
        continue-on-error: true

      - name: Setup ASV machine
        run: |
          # Dynamically detect actual GitHub Actions runner specifications
          mkdir -p .asv/machines

          # Get actual system specifications from the runner
          CPU_INFO=$(lscpu | grep "Model name" | cut -d: -f2 | sed 's/^[ \t]*//' | head -1)
          CPU_COUNT=$(nproc)
          RAM_MB=$(free -m | grep "Mem:" | awk '{print $2}')
          RAM_GB=$((RAM_MB / 1024))
          ARCH=$(uname -m)

          # Use GitHub Actions context variables
          RUNNER_OS="${{ runner.os }}"
          RUNNER_ARCH="${{ runner.arch }}"
          RUNNER_NAME="${{ runner.name }}"

          # Get OS details
          OS_VERSION=$(lsb_release -ds 2>/dev/null | tr -d '"' || echo "Unknown")

          echo "Detected GitHub Actions runner specifications:"
          echo "  Runner Name: $RUNNER_NAME"
          echo "  CPU: $CPU_INFO"
          echo "  Cores: $CPU_COUNT"
          echo "  RAM: ${RAM_GB}GB (${RAM_MB}MB)"
          echo "  Arch: $ARCH"
          echo "  Runner OS: $RUNNER_OS"
          echo "  Runner Arch: $RUNNER_ARCH"
          echo "  OS Version: $OS_VERSION"

          # Create machine config with detected specs
          cat > .asv/machines/github-actions.json << EOF
          {
            "machine": "github-actions",
            "arch": "$ARCH",
            "cpu": "$CPU_INFO",
            "num_cpu": "$CPU_COUNT",
            "os": "$RUNNER_OS $OS_VERSION",
            "ram": "${RAM_GB}GB",
            "version": 1
          }
          EOF

          echo "Machine config created:"
          cat .asv/machines/github-actions.json

          uv run asv machine --machine github-actions

      - name: Run benchmarks
        run: |
          if [ -n "${{ github.event.inputs.benchmark_filter }}" ]; then
            echo "Running filtered benchmarks: ${{ github.event.inputs.benchmark_filter }}"
            uv run asv run --python=3.12 -b "${{ github.event.inputs.benchmark_filter }}" --verbose
          else
            echo "Running benchmarks for HEAD^!"
            uv run asv run --python=3.12 HEAD^! --verbose
          fi

      - name: Show benchmark results on failure
        if: failure()
        run: |
          echo "Benchmark run failed. Checking for logs..."
          find .asv -name "*.log" -exec echo "=== {} ===" \; -exec cat {} \; || true
          echo "Checking ASV results directory..."
          ls -la .asv/ || true
          echo "Checking if schema files exist..."
          ls -la imas_mcp/resources/schemas/ || true

      - name: Generate HTML report
        run: |
          uv run asv publish

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: asv-results
          path: .asv
          retention-days: 90

      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          destination_dir: benchmarks
          keep_files: false

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = '.asv/html/index.json';

            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));
              const benchmarkUrl = `https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/benchmarks/`;
              
              const body = `## 📊 Benchmark Results
              
              Performance benchmarks have been run for this PR.
              
              🔗 **[View full benchmark report](${benchmarkUrl})**
              
              > Results are compared against the main branch. Significant changes will be highlighted in the full report.
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }
